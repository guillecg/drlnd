{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "from p2_continuous_control.agents.agent_td3 import AgentTD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "SCORE_TARGET = 30.0\n",
    "SCORE_WINDOW = 100\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Create folder architecture\n",
    "PROJECT = 'p2_continuous_control'\n",
    "START_TIME = datetime.datetime.now().strftime('%m-%d-%Y_%Hh%Mm')\n",
    "EXPERIMENT_FOLDER = f'{PROJECT}/experiments/{START_TIME}'\n",
    "Path(EXPERIMENT_FOLDER).mkdir(parents=True, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env_path = f'{PROJECT}/Reacher_Linux/Reacher.x86_64'\n",
    "env = UnityEnvironment(file_name=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first option for the environment was DDPG (Deep Deterministic Policy Gradient), an algorithm that has shown a SOTA performance in many environments. DDPG consists in an improved version of DQN, based on the Actor-Critic architecture: the actor learns the policy (mapping of states to actions), while the critic learns the action value function (mapping of states and actions, provided by the actor, to values).\n",
    "\n",
    "However, many drawbacks have been shown by the community and, therefore, a better option should be to use TD3 (Twin Delayed DDPG), an improved DDPG which addresses some of the issues of this algorithm, such as its overestimation of Q-values that leads to the exploitation of bad actions from the policy. To solve DDPG's issues, TD3 uses three different tricks:\n",
    "\n",
    "- **Twin critic networks**: TD3 learns two different value functions/critics, with their corresponding local and target networks, and uses the smaller of the two values as target in the Bellman equation updates. With this trick, the overestimation of bad actions, especially in early stages of the training, is assessed and a more stable performance is achieved.\n",
    "\n",
    "- **Delayed policy updates**: TD3 updates the policy (both local and target networks) less frequently than the value function, thus also dumpening this overestimation of bad actions before updating the critic, and so, contributing to a more stable training.\n",
    "\n",
    "- **Noise regularization**: due to the tendency of deterministic policies to overfit to spikes in values estimates, the addition of noise helps to stabilise training, by reducing the variances of target values.\n",
    "\n",
    "Further improvements are achieved borrowing techniques from other algorithms, such as the replay buffer from DQN and the soft-updates and noise process from DDPG.\n",
    "\n",
    "In addition to this, several hyperparameters have been chosen for training the agent:\n",
    "\n",
    "**Networks parameters**:\n",
    "\n",
    "- actor_fc1_units = 400 # first hidden layer\n",
    "- actor_fc2_units = 300 # second hidden layer\n",
    "- critic_fc1_units = 400 # first hidden laye\n",
    "- critic_fc2_units = 300 # second hidden layer\n",
    "\n",
    "**Hyperparameters**:\n",
    "- batch_size = 128        # minibatch size\n",
    "- buffer_size = int(1e6)  # replay buffer size\n",
    "- learn_every = 20        # how often to update the actor\n",
    "- learn_iterations = 20   # number of update iterations\n",
    "- gamma = 0.995           # discount factor\n",
    "- tau = 0.001             # for soft update of target parameters\n",
    "- actor_lr = 1e-4         # actor learning rate\n",
    "- critic_lr = 1e-3        # critic learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the agent\n",
    "agent = AgentTD3(\n",
    "    state_size=state_size,\n",
    "    action_size=action_size,\n",
    "    hyperparams=dict(),\n",
    "    device=DEVICE,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tWindow Score: 16.40: 28.07\tWindow Score: 16.40\n",
      "Episode 167\tEpisode total score: 35.07\tWindow Score: 30.08\n",
      "Environment solved in 167 episodes!\tWindow Score: 30.08\n",
      "Saving weights into p2_continuous_control/experiments/04-26-2020_19h45m folder...\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "n_episodes = 250   # maximum number of training episodes\n",
    "max_t = 1000       # maximum number of timesteps per episode\n",
    "\n",
    "scores = []                                 # scores for each episode\n",
    "scores_window = deque(maxlen=SCORE_WINDOW)  # last 100 scores\n",
    "scores_window_means = []                    # average max scores for each episode\n",
    "\n",
    "# training loop\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "    states = env_info.vector_observations              # get the current stat\n",
    "    agent.reset()                                      # initialize agents\n",
    "    score = np.zeros(num_agents)                       # initialize scores\n",
    "\n",
    "    for t in range(max_t):\n",
    "        actions = agent.select_action(states)       # get the action from the agent\n",
    "        env_info = env.step(actions)[brain_name]    # send the action to the environment\n",
    "        next_states = env_info.vector_observations  # get the next state\n",
    "        rewards = env_info.rewards                  # get the reward\n",
    "        dones = env_info.local_done                 # see if episode has finished\n",
    "\n",
    "        # save experience tuple (of each agent) into replay buffer\n",
    "        for i_agent in range(0, num_agents):\n",
    "            experience = (\n",
    "                states[i_agent],\n",
    "                actions[i_agent],\n",
    "                rewards[i_agent],\n",
    "                next_states[i_agent],\n",
    "                dones[i_agent]\n",
    "            )\n",
    "            agent.memory.add(data=experience)\n",
    "\n",
    "        states = next_states  # roll over states to next time step\n",
    "        score += rewards      # update the scores\n",
    "\n",
    "        # Train each agent\n",
    "        agent.learn_batch(timestep=t)\n",
    "\n",
    "        if np.any(dones):\n",
    "            break\n",
    "\n",
    "    # Score is updated for each agent, therefore use mean as an estimate\n",
    "    score = np.mean(score)\n",
    "\n",
    "    scores.append(score)\n",
    "    scores_window.append(score)\n",
    "\n",
    "    window_score_mean = np.mean(scores_window)  # save mean of window scores\n",
    "    scores_window_means.append(window_score_mean)\n",
    "\n",
    "    print(\n",
    "        '\\rEpisode {}\\tEpisode total score: {:.2f}\\tWindow Score: {:.2f}'\n",
    "        .format(i_episode, score, window_score_mean),\n",
    "        end=\"\"\n",
    "    )\n",
    "\n",
    "    if i_episode % 100 == 0:\n",
    "        print(\n",
    "            '\\rEpisode {}\\tWindow Score: {:.2f}'\n",
    "            .format(i_episode, window_score_mean)\n",
    "        )\n",
    "\n",
    "    if window_score_mean >= SCORE_TARGET:\n",
    "        print(\n",
    "            '\\nEnvironment solved in {:d} episodes!\\tWindow Score: {:.2f}'\n",
    "            .format(i_episode, window_score_mean)\n",
    "        )\n",
    "\n",
    "        print(f'Saving weights into {EXPERIMENT_FOLDER} folder...')\n",
    "        torch.save(\n",
    "            agent.actor_local.state_dict(),\n",
    "            f'{EXPERIMENT_FOLDER}/weights_actor_episode_{i_episode}.pth'\n",
    "        )\n",
    "        torch.save(\n",
    "            agent.critic_local.state_dict(),\n",
    "            f'{EXPERIMENT_FOLDER}/weights_critic_episode_{i_episode}.pth'\n",
    "        )\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure into p2_continuous_control/experiments/04-26-2020_19h45m folder...\n"
     ]
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores) + 1), scores)\n",
    "plt.plot(np.arange(1, len(scores) + 1), scores_window_means, label='mean')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n",
    "# save figure to fileP2 - Continuous Control\n",
    "print(f'Saving figure into {EXPERIMENT_FOLDER} folder...')\n",
    "fig.savefig(f'{EXPERIMENT_FOLDER}/scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Further improvements\n",
    "\n",
    "I could not tune neither the delayed update nor the noise addition, and I think that this should be a must since I've seen other implementations outperforming mine by far. The problem of this is the huge amount of possibilities and, thus, a directed search must be performed, borrowing insights from other works and implementations.\n",
    "\n",
    "In addition, I performed no architecture search, which I think could help me to fine-tune the performance for each environment.\n",
    "\n",
    "#### 5.2. Other algorithms\n",
    "\n",
    "Other algorithms that I think could be interesting to benchmark with TD3 are PPO and TRPO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. References\n",
    "\n",
    "**TD3 paper**: https://arxiv.org/abs/1802.09477\n",
    "\n",
    "**TD3 explanations**:\n",
    "- https://spinningup.openai.com/en/latest/algorithms/td3.html\n",
    "- https://towardsdatascience.com/td3-learning-to-run-with-ai-40dfc512f93\n",
    "- https://towardsdatascience.com/reinforcement-learning-ddpg-and-td3-for-news-recommendation-d3cddec26011\n",
    "\n",
    "**TD3 implementations**:\n",
    "- https://github.com/djbyrne/TD3\n",
    "- https://github.com/sweetice/Deep-reinforcement-learning-with-pytorch\n",
    "- https://github.com/wiflore/DRL_Continuous_Control-TD3_Pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
